// OpenAI API integration for GPT-5-mini

import OpenAI from 'openai';
import type { AIResponse } from '@/lib/types';

// Centralized model configuration for the entire Hysio platform
export const HYSIO_LLM_MODEL = 'gpt-5-mini' as const;

// Initialize OpenAI client
let openaiClient: OpenAI | null = null;

function getOpenAIClient(): OpenAI {
  if (!openaiClient) {
    const apiKey = process.env.OPENAI_API_KEY;
    if (!apiKey) {
      console.warn('OPENAI_API_KEY environment variable is not set - using mock responses');
      // Return a mock client that will be handled in the API functions
      throw new Error('OPENAI_API_KEY environment variable is not set');
    }
    openaiClient = new OpenAI({ apiKey });
  }
  return openaiClient;
}

export interface OpenAICompletionOptions {
  model?: string; // Default to gpt-5-mini
  temperature?: number; // 0-2, controls randomness
  maxTokens?: number; // Maximum tokens in response
  top_p?: number; // 0-1, nucleus sampling
  frequency_penalty?: number; // -2 to 2, penalize frequent tokens
  presence_penalty?: number; // -2 to 2, penalize existing tokens
  stop?: string | string[]; // Stop sequences
  stream?: boolean; // Enable streaming
  user?: string; // Unique user identifier
}

export async function generateContentWithOpenAI(
  systemPrompt: string,
  userPrompt: string,
  options: OpenAICompletionOptions = {}
): Promise<AIResponse> {
  try {
    const {
      model = HYSIO_LLM_MODEL,
      temperature = 1.0, // GPT-5-mini only supports temperature = 1
      top_p = 1.0,
      frequency_penalty = 0,
      presence_penalty = 0,
      stop,
      user,
    } = options;

    const maxTokens =
      options.maxTokens ??
      (options as { max_tokens?: number }).max_tokens ?? // Backwards compatibility with previous naming
      2000;

    // Check if API key is available
    if (!process.env.OPENAI_API_KEY) {
      console.warn('OPENAI_API_KEY not set - returning demo content');
      return generateDemoContent(systemPrompt, userPrompt);
    }

    // Get OpenAI client
    const client = getOpenAIClient();

    // Create completion
    const completion = await client.chat.completions.create({
      model,
      messages: [
        { role: 'system', content: systemPrompt },
        { role: 'user', content: userPrompt }
      ],
      temperature,
      max_tokens: maxTokens,
      top_p,
      frequency_penalty,
      presence_penalty,
      stop,
      user,
    });

    const choice = completion.choices[0];

    if (!choice || !choice.message?.content) {
      throw new Error('No content generated by OpenAI');
    }

    return {
      success: true,
      content: choice.message.content.trim(),
      model: completion.model,
      usage: completion.usage ? {
        prompt_tokens: completion.usage.prompt_tokens,
        completion_tokens: completion.usage.completion_tokens,
        total_tokens: completion.usage.total_tokens,
      } : undefined,
    };

  } catch (error) {
    console.error('OpenAI completion error:', error);

    // If error is due to missing API key, return demo content
    if (error instanceof Error && error.message.includes('OPENAI_API_KEY')) {
      console.warn('Falling back to demo content due to missing API key');
      return generateDemoContent(systemPrompt, userPrompt);
    }

    let errorMessage = 'Failed to generate content';

    if (error instanceof OpenAI.APIError) {
      errorMessage = `OpenAI API error: ${error.message}`;

      // Handle specific error types
      if (error.status === 429) {
        errorMessage = 'Rate limit exceeded. Please try again later.';
      } else if (error.status === 401) {
        errorMessage = 'Invalid OpenAI API key.';
      } else if (error.status === 402) {
        errorMessage = 'Insufficient OpenAI credits.';
      } else if (error.status === 503) {
        errorMessage = 'OpenAI service temporarily unavailable.';
      }
    } else if (error instanceof Error) {
      errorMessage = `OpenAI error: ${error.message}`;
    }

    return {
      success: false,
      error: errorMessage,
    };
  }
}

// Demo content generator for when API key is not available
function generateDemoContent(systemPrompt: string, userPrompt: string): AIResponse {
  // Extract section type from system prompt
  let sectionType = 'general';
  if (systemPrompt.includes('introduction')) sectionType = 'introduction';
  else if (systemPrompt.includes('session_summary')) sectionType = 'session_summary';
  else if (systemPrompt.includes('diagnosis')) sectionType = 'diagnosis';
  else if (systemPrompt.includes('treatment_plan')) sectionType = 'treatment_plan';
  else if (systemPrompt.includes('self_care')) sectionType = 'self_care';
  else if (systemPrompt.includes('warning_signs')) sectionType = 'warning_signs';
  else if (systemPrompt.includes('follow_up')) sectionType = 'follow_up';

  const demoContent: Record<string, string> = {
    introduction: `Beste patiënt,

Hartelijk welkom bij uw fysiotherapie behandeling. Deze samenvatting geeft u een duidelijk overzicht van uw bezoek van vandaag en wat u kunt verwachten in de komende periode.

Wij zijn er om u te helpen bij uw herstel en staan altijd klaar voor uw vragen.`,

    session_summary: `Tijdens ons gesprek vandaag hebben we uw klachten uitgebreid besproken:

• Pijn in de onderrug die ongeveer 3 weken geleden is begonnen
• Stijfheid 's ochtends die na ongeveer 30 minuten vermindert
• Moeite met bukken en tillen
• Geen uitstraling naar de benen
• Klachten zijn ontstaan na het verhuizen

Bij het onderzoek vonden we beperkte bewegelijkheid in de lage rug en gespannen spieren.`,

    diagnosis: `Wat er aan de hand is:

U heeft last van een niet-specifieke lage rugpijn. Dit betekent dat uw rugspieren en gewrichten gespannen en geprikkeld zijn geraakt, waarschijnlijk door de ongewone belasting tijdens het verhuizen.

Dit is een veelvoorkomende aandoening die goed te behandelen is. Uw ruggengraat zelf is niet beschadigd - het gaat om spier- en gewrichtsproblematiek die met de juiste aanpak goed herstelt.`,

    treatment_plan: `Uw behandelplan:

Wij gaan werken aan het verminderen van uw pijn en het herstellen van uw bewegelijkheid. Het behandelplan bestaat uit:

1. Manuele therapie om uw gewrichten soepeler te maken
2. Oefeningen om uw rugspieren te versterken
3. Advisering over goede houdingen en bewegingen
4. Geleidelijke opbouw van uw normale activiteiten

We verwachten dat u binnen 4-6 weken duidelijke verbetering zult merken.`,

    self_care: `Wat u zelf kunt doen:

**Dagelijkse oefeningen:**
1. Knie-borst oefening: trek uw knieën naar uw borst, houd 30 seconden vast (5x)
2. Bekkenkantel: lig op uw rug, span buikspieren aan, druk onderrug tegen de grond (10x)
3. Lopen: begin met 10 minuten per dag, bouw langzaam op

**Belangrijke tips:**
• Gebruik warmte (warme douche of warmtepack) voor stijfheid
• Vermijd lang zitten, sta elke 30 minuten op
• Til met gebogen knieën, niet met uw rug
• Blijf actief binnen uw pijngrens`,

    warning_signs: `Neem contact met ons op als u:

• Plotseling veel meer pijn krijgt
• Tintelingen of gevoelloosheid in uw benen ontwikkelt
• Moeite krijgt met plassen of ontlasting
• Pijn uitstraalt naar beide benen
• Koorts krijgt in combinatie met rugpijn

Bij dringende klachten kunt u ons bellen op 020-1234567. Voor niet-urgente vragen kunt u mailen naar info@fysiohysio.nl`,

    follow_up: `Vervolgafspraken:

Uw volgende afspraak is over 1 week. We gaan dan kijken hoe u reageert op de behandeling en passen waar nodig het plan aan.

Tussen nu en de volgende afspraak kunt u:
• Uw oefeningen dagelijks doen
• Contact opnemen bij vragen of zorgen
• Uw activiteiten geleidelijk uitbreiden

U kunt online een afspraak inplannen via onze website of bellen naar 020-1234567.`
  };

  return {
    success: true,
    content: demoContent[sectionType] || 'Demo inhoud voor EduPack sectie. Voor volledige AI-gegenereerde content, configureer uw OpenAI API sleutel.',
    model: 'demo-model',
    usage: {
      prompt_tokens: 100,
      completion_tokens: 200,
      total_tokens: 300,
    },
  };
}

export interface OpenAIStreamOptions extends OpenAICompletionOptions {
  onChunk?: (chunk: string) => void;
  onComplete?: (fullContent: string) => void;
  onError?: (error: string) => void;
}

export async function generateContentStreamWithOpenAI(
  systemPrompt: string,
  userPrompt: string,
  options: OpenAIStreamOptions = {}
): Promise<AIResponse> {
  try {
    const {
      model = HYSIO_LLM_MODEL,
      temperature = 1.0, // GPT-5-mini only supports temperature = 1
      top_p = 1.0,
      frequency_penalty = 0,
      presence_penalty = 0,
      stop,
      user,
      onChunk,
      onComplete,
      onError,
    } = options;

    const maxTokens =
      options.maxTokens ??
      (options as { max_tokens?: number }).max_tokens ?? // Backwards compatibility with previous naming
      2000;

    // Get OpenAI client
    const client = getOpenAIClient();

    // Create streaming completion
    const stream = await client.chat.completions.create({
      model,
      messages: [
        { role: 'system', content: systemPrompt },
        { role: 'user', content: userPrompt }
      ],
      temperature,
      max_tokens: maxTokens,
      top_p,
      frequency_penalty,
      presence_penalty,
      stop,
      user,
      stream: true,
    });

    let fullContent = '';
    let usage: any = undefined;
    let modelUsed = model;

    try {
      for await (const chunk of stream) {
        const choice = chunk.choices[0];
        
        if (choice?.delta?.content) {
          const content = choice.delta.content;
          fullContent += content;
          onChunk?.(content);
        }
        
        // Update model and usage from chunk
        if (chunk.model) {
          modelUsed = chunk.model;
        }
        if (chunk.usage) {
          usage = chunk.usage;
        }
      }
      
      onComplete?.(fullContent);

      return {
        success: true,
        content: fullContent.trim(),
        model: modelUsed,
        usage: usage ? {
          prompt_tokens: usage.prompt_tokens,
          completion_tokens: usage.completion_tokens,
          total_tokens: usage.total_tokens,
        } : undefined,
      };

    } catch (streamError) {
      const errorMessage = streamError instanceof Error ? streamError.message : 'Stream processing error';
      onError?.(errorMessage);
      throw streamError;
    }

  } catch (error) {
    console.error('OpenAI streaming error:', error);
    
    let errorMessage = 'Failed to generate streaming content';
    
    if (error instanceof OpenAI.APIError) {
      errorMessage = `OpenAI streaming error: ${error.message}`;
    } else if (error instanceof Error) {
      errorMessage = `OpenAI streaming error: ${error.message}`;
    }

    options.onError?.(errorMessage);

    return {
      success: false,
      error: errorMessage,
    };
  }
}

// Function to estimate token count (rough approximation)
export function estimateTokenCount(text: string): number {
  // Rough approximation: 1 token ≈ 4 characters for English text
  // This is not accurate but gives a ballpark estimate
  return Math.ceil(text.length / 4);
}

// Function to estimate cost (approximate)
export function estimateCompletionCost(
  promptTokens: number,
  completionTokens: number,
  model: string = HYSIO_LLM_MODEL
): number {
  // GPT-4o pricing (as of 2024 - check OpenAI pricing for current rates)
  // Input: $0.0025 per 1K tokens
  // Output: $0.01 per 1K tokens
  const inputCost = (promptTokens / 1000) * 0.0025;
  const outputCost = (completionTokens / 1000) * 0.01;
  
  return inputCost + outputCost;
}

// Utility function to validate model availability
export function isValidOpenAIModel(model: string): boolean {
  const validModels = [
    'gpt-5-mini',
    'gpt-4o',
    'gpt-4o-mini',
    'gpt-4',
    'gpt-4-turbo',
    'gpt-3.5-turbo',
  ];

  return validModels.includes(model);
}